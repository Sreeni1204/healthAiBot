{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc44fe0c",
   "metadata": {},
   "source": [
    "# HealthAIBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f0f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export env variables before running this block\n",
    "import os\n",
    "\n",
    "class KEYS:\n",
    "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-openai-api-key\")\n",
    "    TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"your-tavily-api-key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4e6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "# healthAiBot/healthaibot/utils/utils.py\n",
    "\"\"\"\n",
    "Utility functions for HealthBot operations.\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "class HealthBotState(BaseModel):\n",
    "    # Allow either raw dicts or LangChain BaseMessage objects\n",
    "    messages: List[Any] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of conversation messages (dicts or LangChain messages) including tool calls for traceability\"\n",
    "    )\n",
    "    topic: Optional[str] = None\n",
    "    focus: Optional[str] = None\n",
    "    search_results: Optional[str] = None\n",
    "    summary: Optional[str] = None\n",
    "    question: Optional[str] = None\n",
    "    quiz_question: Optional[str] = None\n",
    "    quiz_answer: Optional[str] = None\n",
    "    quiz_grade: Optional[str] = None\n",
    "    grading: Optional[str] = None\n",
    "    continue_flag: Optional[str] = None\n",
    "    previous_questions: List[str] = Field(default_factory=list)\n",
    "    tool_call_events: List[Any] = Field(\n",
    "        default_factory=list, \n",
    "        description=\"Legacy tool call tracking - use messages for better traceability\"\n",
    "    )\n",
    "    llm: Optional[Any] = None\n",
    "\n",
    "\n",
    "class HealthBotUtils:\n",
    "    \"\"\"\n",
    "    Utility functions for HealthBot operations.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_type: str,\n",
    "        model_name: str,\n",
    "        temperature: float = 0.7,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the HealthBotUtils class.\n",
    "        Parameters:\n",
    "            llm_type: Type of LLM to use ('openai' or 'ollama').\n",
    "            model_name: Name of the model to use.\n",
    "            temperature: Sampling temperature for the LLM.\n",
    "        \"\"\"\n",
    "        self.llm_type = llm_type\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def get_llm(\n",
    "        self,\n",
    "    ) -> ChatOpenAI | ChatOllama:\n",
    "        \"\"\"\n",
    "        Get the LLM instance based on the specified type.\n",
    "        Returns:\n",
    "            An instance of ChatOpenAI or ChatOllama.\n",
    "        \"\"\"\n",
    "        if self.llm_type == \"openai\":\n",
    "            return ChatOpenAI(\n",
    "                model=self.model_name,\n",
    "                temperature=self.temperature\n",
    "            )\n",
    "        elif self.llm_type == \"ollama\":\n",
    "            return ChatOllama(\n",
    "                model=self.model_name,\n",
    "                temperature=self.temperature\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported LLM type. Choose 'openai' or 'ollama'.\")\n",
    "\n",
    "    def reset_state(\n",
    "        self,\n",
    "        llm: ChatOpenAI | ChatOllama,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Reset the state of the HealthBot.\n",
    "        \"\"\"\n",
    "        # Clear previous health information to maintain privacy\n",
    "        return HealthBotState(llm=llm)\n",
    "\n",
    "    def parse_quiz(\n",
    "        self,\n",
    "        quiz_text: str,\n",
    "    ) -> tuple[str, list[str]]:\n",
    "        \"\"\"\n",
    "        Parse the quiz text into a question and options.\n",
    "        Now handles both single questions and multiple choice questions.\n",
    "        \"\"\"\n",
    "        # Simple parser to split question and options\n",
    "        lines = quiz_text.strip().split('\\n')\n",
    "        question = \"\"\n",
    "        options = []\n",
    "        \n",
    "        for line in lines:\n",
    "            # Check for multiple choice options\n",
    "            if line.startswith(\"a)\") or line.startswith(\"b)\") or line.startswith(\"c)\") or line.startswith(\"d)\"):\n",
    "                options.append(line)\n",
    "            elif line.lower().startswith(\"question:\"):\n",
    "                question = line[len(\"Question:\"):].strip()\n",
    "            elif line and not line.startswith(\"summary:\") and not line.startswith(\"previous questions:\"):\n",
    "                if question:\n",
    "                    question += \" \" + line.strip()\n",
    "                else:\n",
    "                    question = line.strip()\n",
    "        \n",
    "        # If no options found, this is a single question (not MCQ)\n",
    "        # Return empty options list to indicate open-ended question\n",
    "        return question.strip(), options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4596a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility functions for HealthBot agent operations with quiz flow enforcement.\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool(\"tavily_search_tool\", return_direct=True)\n",
    "def tavily_search_tool(topic: str) -> str:\n",
    "    \"\"\"Search authoritative medical sources (NIH, Mayo Clinic, WebMD) for the given topic.\"\"\"\n",
    "    if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "        raise ValueError(\"Missing Tavily API key. Please export TAVILY_API_KEY before running the agent.\")\n",
    "    search = TavilySearch()\n",
    "    query = f\"{topic} site:nih.gov OR site:mayoclinic.org OR site:webmd.com\"\n",
    "    return str(search.invoke(query))\n",
    "\n",
    "\n",
    "class GraphHelper:\n",
    "    def __init__(self) -> None:  # No special init needed\n",
    "        pass\n",
    "\n",
    "    # ---------------- Core Interaction Nodes -----------------\n",
    "    def ask_patient(self, state: HealthBotState) -> HealthBotState:\n",
    "        try:\n",
    "            topic = input(\"What health topic or medical condition would you like to learn about? \")\n",
    "        except EOFError:\n",
    "            print(\"\\nInput ended unexpectedly. Exiting HealthBot.\")\n",
    "            exit(0)\n",
    "        state.topic = topic\n",
    "        print(f\"You have chosen to learn about: {state.topic}\")\n",
    "        state.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"I want to learn about {state.topic}.\",\n",
    "            \"action\": \"topic_selection\",\n",
    "            \"timestamp\": str(datetime.now())\n",
    "        })\n",
    "        return state\n",
    "\n",
    "    def generate_assistant_message(self, state: HealthBotState) -> HealthBotState:\n",
    "        # Seed conversation and include an assistant message that simulates a tool call request.\n",
    "        state.messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful medical information assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"I want to learn about {state.topic}.\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"Initiating search for {state.topic} using tavily_search_tool.\", \"tool_calls\": [\n",
    "                {\"id\": \"call_tavily_1\", \"name\": \"tavily_search_tool\", \"arguments\": {\"topic\": state.topic}}\n",
    "            ]}\n",
    "        ]\n",
    "        return state\n",
    "\n",
    "    def ask_for_focus(self, state: HealthBotState) -> HealthBotState:\n",
    "        if not state.focus:\n",
    "            try:\n",
    "                focus = input(\"Do you want to focus on a specific aspect (e.g., symptoms, treatment, prevention)? If yes, enter it, otherwise press Enter: \")\n",
    "            except EOFError:\n",
    "                print(\"\\nInput ended unexpectedly. Using no specific focus.\")\n",
    "                focus = \"\"\n",
    "            if focus.strip():\n",
    "                state.focus = focus.strip()\n",
    "            state.messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Focus selection: {state.focus if state.focus else 'No specific focus'}\",\n",
    "                \"action\": \"focus_selection\",\n",
    "                \"timestamp\": str(datetime.now())\n",
    "            })\n",
    "        return state\n",
    "\n",
    "    def search_tavily(self, state: HealthBotState) -> HealthBotState:\n",
    "        state.tool_call_events.append({\n",
    "            \"event\": \"tool_call\", \"tool\": \"tavily_search_tool\", \"topic\": state.topic\n",
    "        })\n",
    "        return state\n",
    "\n",
    "    def summarize_results(self, state: HealthBotState) -> HealthBotState:\n",
    "        llm = state.llm\n",
    "        focus = getattr(state, 'focus', None)\n",
    "        # If no real search results (API key missing or fallback placeholder), avoid hallucination\n",
    "        if not state.search_results or 'Missing Tavily API key' in state.search_results:\n",
    "            state.summary = (\n",
    "                \"Search unavailable because Tavily API key is missing. \"\n",
    "                \"Set TAVILY_API_KEY and restart to generate an evidence-based summary.\"\n",
    "            )\n",
    "            return state\n",
    "        base_prompt = (\n",
    "            \"You are a medical information assistant. Summarize the search results for a patient.\\n\\n\"\n",
    "            \"MANDATORY FORMAT & RULES (FOLLOW EXACTLY):\\n\"\n",
    "            \"1. Output MUST be EXACTLY 3 TO 4 paragraphs. No other number is acceptable.\\n\"\n",
    "            \"2. Paragraphs are separated by ONE blank line (a single empty line).\\n\"\n",
    "            \"3. Each paragraph MUST be between 3 and 5 sentences (inclusive).\\n\"\n",
    "            \"4. Use ONLY information present in the search results. If something isn't there, do NOT invent it.\\n\"\n",
    "            \"5. If an expected aspect is missing, explicitly state: 'The search results do not provide information about <missing aspect>'.\\n\"\n",
    "            \"6. Do NOT include bullet lists, numbering, headings, markdown, or metadata. Plain paragraphs only.\\n\"\n",
    "            \"7. If you cannot satisfy ALL rules with given content, write EXACTLY this sentence alone: 'The search results are insufficient to produce a compliant summary.'\\n\"\n",
    "            \"8. Do NOT mention these instructions or justify your formatting.\\n\\n\"\n",
    "            \"QUALITY GUIDELINES:\\n\"\n",
    "            \"- Use clear, patient-friendly language.\\n\"\n",
    "            \"- Avoid redundancy; group related facts.\\n\"\n",
    "            \"- Prefer concrete facts over vague generalities.\\n\\n\"\n",
    "            \"ACCEPTABLE EXAMPLE (3 paragraphs):\\n\"\n",
    "            \"Paragraph 1: Overview sentences 1-5.\\n\"\n",
    "            \"\\nParagraph 2: Focused detail sentences 1-4.\\n\"\n",
    "            \"\\nParagraph 3: Limitations + missing info sentences 1-3.\\n\\n\"\n",
    "            \"UNACCEPTABLE EXAMPLES (DO NOT DO):\\n\"\n",
    "            \"- A single long block (fails rule 1).\\n\"\n",
    "            \"- 5 paragraphs (fails rule 1).\\n\"\n",
    "            \"- Paragraphs with 1â€“2 sentences (fails rule 3).\\n\"\n",
    "            \"- Bullet lists or headings (fails rule 6).\\n\\n\"\n",
    "        )\n",
    "        if focus:\n",
    "            base_prompt += f\"FOCUS REQUIREMENT: Emphasize information about '{focus}'.\\n\\n\"\n",
    "        base_prompt += (\n",
    "            \"FORMAT: Write EXACTLY 3 TO 4 paragraphs separated by blank lines. Do not include headers, bullet points, or numbered lists.\\n\\n\"\n",
    "            \"SEARCH RESULTS TO SUMMARIZE:\\n\"\n",
    "        )\n",
    "        prompt = base_prompt + (state.search_results or \"\")\n",
    "        state.messages.append({\n",
    "            \"role\": \"user\", \"content\": f\"Requesting summary generation for topic: {state.topic}\",\n",
    "            \"action\": \"summarize_results\", \"focus\": focus if focus else \"None\"\n",
    "        })\n",
    "        if llm is None:\n",
    "            state.summary = \"LLM not initialized.\"\n",
    "            return state\n",
    "        summary = llm.invoke(prompt)\n",
    "        state.summary = summary.content if hasattr(summary, 'content') else str(summary)\n",
    "        state.messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Generated summary for {state.topic} ({len(state.summary)} characters)\",\n",
    "            \"action\": \"summarize_results_complete\",\n",
    "            \"summary_length\": str(len(state.summary))\n",
    "        })\n",
    "        return state\n",
    "\n",
    "    def present_summary(self, state: HealthBotState) -> HealthBotState:\n",
    "        print(\"\\nHere is a summary of what you asked about:\\n\")\n",
    "        print(state.summary)\n",
    "        return state\n",
    "\n",
    "    def comprehension_prompt(self, state: HealthBotState) -> HealthBotState:\n",
    "        try:\n",
    "            input(\"\\nPress Enter when you are ready to take a comprehension check.\")\n",
    "        except EOFError:\n",
    "            print(\"\\nInput ended unexpectedly. Proceeding with comprehension check.\")\n",
    "        return state\n",
    "\n",
    "    # ---------------- Quiz Flow Nodes -----------------\n",
    "    def create_quiz(self, state: HealthBotState) -> HealthBotState:\n",
    "        llm = state.llm\n",
    "        previous = list(getattr(state, 'previous_questions', []))\n",
    "        prompt = (\n",
    "            \"Create ONE comprehension question based EXCLUSIVELY on the provided summary below.\\n\\n\"\n",
    "            \"STRICT REQUIREMENTS:\\n\"\n",
    "            \"1. Create ONLY ONE question (open-ended)\\n\"\n",
    "            \"2. The question must be answerable ONLY using information from the summary\\n\"\n",
    "            \"3. No outside knowledge\\n\"\n",
    "            \"4. Test key understanding of the summary\\n\"\n",
    "            \"5. Do NOT reveal the answer\\n\"\n",
    "            \"6. Do NOT repeat any previous questions\\n\\n\"\n",
    "            \"FORMAT: Output just the question text.\\n\\n\"\n",
    "            f\"SUMMARY:\\n{state.summary}\\n\\n\"\n",
    "            f\"PREVIOUS QUESTIONS:\\n{previous if previous else 'None'}\\n\\n\"\n",
    "            \"QUESTION:\"\n",
    "        )\n",
    "        state.messages.append({\n",
    "            \"role\": \"user\", \"content\": f\"Requesting quiz question for {state.topic}\",\n",
    "            \"action\": \"create_quiz\", \"previous_questions_count\": str(len(previous))\n",
    "        })\n",
    "        if llm is None:\n",
    "            state.quiz_question = \"LLM not initialized to create quiz question.\"\n",
    "            return state\n",
    "        raw = llm.invoke(prompt)\n",
    "        raw_text = raw.content.strip() if hasattr(raw, 'content') else str(raw).strip()\n",
    "        candidate_lines = [ln.strip() for ln in raw_text.split('\\n') if ln.strip()]\n",
    "        selected = \"\"\n",
    "        for ln in candidate_lines:\n",
    "            if '?' in ln and not selected:\n",
    "                selected = ln\n",
    "            elif '?' in ln and selected:\n",
    "                state.messages.append({\n",
    "                    \"role\": \"assistant\", \"content\": f\"Discarded extra question: {ln[:80]}\",\n",
    "                    \"action\": \"create_quiz_sanitizer\"\n",
    "                })\n",
    "        if not selected and candidate_lines:\n",
    "            selected = candidate_lines[0]\n",
    "        for prefix in [\"question:\", \"q:\", \"q1:\"]:\n",
    "            if selected.lower().startswith(prefix):\n",
    "                selected = selected[len(prefix):].strip()\n",
    "        if not selected.endswith('?'):\n",
    "            selected = selected.rstrip('.') + '?'\n",
    "        if selected not in previous:\n",
    "            previous.append(selected)\n",
    "        else:\n",
    "            state.messages.append({\n",
    "                \"role\": \"assistant\", \"content\": \"Duplicate question detected (kept).\",\n",
    "                \"action\": \"create_quiz_duplicate\"\n",
    "            })\n",
    "        state.previous_questions = previous\n",
    "        state.quiz_question = selected\n",
    "        preview = selected[:100] + \"...\" if len(selected) > 100 else selected\n",
    "        state.messages.append({\n",
    "            \"role\": \"assistant\", \"content\": f\"Generated sanitized quiz question for {state.topic}\",\n",
    "            \"action\": \"create_quiz_complete\", \"question_preview\": preview\n",
    "        })\n",
    "        return state\n",
    "\n",
    "    def present_quiz(self, state: HealthBotState) -> HealthBotState:\n",
    "        print(\"\\nQuiz Question:\\n\")\n",
    "        print(state.quiz_question)\n",
    "        return state\n",
    "\n",
    "    def get_quiz_answer(self, state: HealthBotState) -> HealthBotState:\n",
    "        try:\n",
    "            answer = input(\"\\nEnter your answer to the quiz question: \")\n",
    "        except EOFError:\n",
    "            print(\"\\nInput ended unexpectedly. Exiting HealthBot.\")\n",
    "            exit(0)\n",
    "        state.quiz_answer = answer\n",
    "        state.messages.append({\n",
    "            \"role\": \"user\", \"content\": f\"Quiz answer: {answer}\",\n",
    "            \"action\": \"quiz_answer_submission\", \"question\": state.quiz_question,\n",
    "            \"timestamp\": str(datetime.now())\n",
    "        })\n",
    "        return state\n",
    "\n",
    "    def grade_quiz(self, state: HealthBotState) -> HealthBotState:\n",
    "        llm = state.llm\n",
    "        prompt = (\n",
    "            \"You are a strict grading assistant. You must grade the user's answer using ONLY the provided SUMMARY.\\n\"\n",
    "            \"If the answer invents information not present in the SUMMARY, penalize it.\\n\"\n",
    "            \"If the answer contradicts the SUMMARY, penalize it.\\n\"\n",
    "            \"If the answer partially matches, give a middle grade.\\n\"\n",
    "            \"If the answer fully and accurately reflects key points in the SUMMARY, give a high grade.\\n\\n\"\n",
    "            \"RESTRICTIONS:\\n\"\n",
    "            \"- You SHOULD NOT use any knowledge outside the SUMMARY.\\n\"\n",
    "            \"- Do NOT add new facts.\\n\"\n",
    "            \"- Justification MUST cite only facts/phrases that appear in the SUMMARY.\\n\\n\"\n",
    "            \"ALLOWED GRADES:\\nA = Completely accurate based only on SUMMARY\\nB = Mostly accurate, minor omissions\\nC = Partially accurate, missing important points\\nD = Limited accuracy, several errors or omissions\\nF = Incorrect or largely not based on SUMMARY\\n\\n\"\n",
    "            \"OUTPUT FORMAT (must follow exactly, no extra lines):\\n\"\n",
    "            \"Grade: <A|B|C|D|F>\\nJustification: <one concise sentence using only SUMMARY info>\\n\\n\"\n",
    "            f\"SUMMARY (sole source of truth):\\n{state.summary}\\n\\n\"\n",
    "            f\"QUESTION:\\n{state.quiz_question}\\n\\n\"\n",
    "            f\"USER ANSWER:\\n{state.quiz_answer}\\n\\n\"\n",
    "            \"Now produce ONLY the required two-line format.\"\n",
    "        )\n",
    "        state.messages.append({\n",
    "            \"role\": \"user\", \"content\": f\"Requesting grade for quiz on {state.topic}\",\n",
    "            \"action\": \"grade_quiz\", \"user_answer\": state.quiz_answer or \"\"\n",
    "        })\n",
    "        if llm is None:\n",
    "            state.grading = \"LLM not initialized to grade quiz answer.\"\n",
    "            return state\n",
    "        grading = llm.invoke(prompt)\n",
    "        raw_text = grading.content if hasattr(grading, 'content') else str(grading)\n",
    "\n",
    "        # Post-process to enforce exact format.\n",
    "        lines = [line.strip() for line in raw_text.split('\\n') if line.strip()]\n",
    "        grade_val = None\n",
    "        justification_val = None\n",
    "        for line in lines:\n",
    "            low = line.lower()\n",
    "            if low.startswith('grade:') and grade_val is None:\n",
    "                possible = line.split(':', 1)[1].strip().upper()\n",
    "                if possible and possible[0] in {'A','B','C','D','F'}:\n",
    "                    grade_val = possible[0]\n",
    "            elif low.startswith('justification:') and justification_val is None:\n",
    "                justification_val = line.split(':', 1)[1].strip()\n",
    "\n",
    "        # Fallback extraction if not properly structured.\n",
    "        if grade_val is None:\n",
    "            # Search for standalone letter\n",
    "            for cand in ['A','B','C','D','F']:\n",
    "                if f' {cand} ' in f' {raw_text} ':\n",
    "                    grade_val = cand\n",
    "                    break\n",
    "        if grade_val is None:\n",
    "            grade_val = 'F'  # default fail-safe\n",
    "        if not justification_val:\n",
    "            justification_val = 'Answer lacks sufficient alignment with the provided summary.'\n",
    "\n",
    "        # Truncate overly long justification\n",
    "        if len(justification_val) > 280:\n",
    "            justification_val = justification_val[:277] + '...'\n",
    "\n",
    "        state.grading = f\"Grade: {grade_val}\\nJustification: {justification_val}\"\n",
    "        preview = (state.grading[:100] + \"...\") if len(state.grading) > 100 else state.grading\n",
    "        state.messages.append({\n",
    "            \"role\": \"assistant\", \"content\": f\"Completed grading for {state.topic}\",\n",
    "            \"action\": \"grade_quiz_complete\", \"grading_preview\": preview\n",
    "        })\n",
    "        return state\n",
    "\n",
    "    def present_feedback(self, state: HealthBotState) -> HealthBotState:\n",
    "        print(\"\\nYour grade and feedback:\\n\")\n",
    "        grading_text = state.grading or \"\"\n",
    "        lines = grading_text.strip().split('\\n')\n",
    "        grade_line = \"\"\n",
    "        justification_line = \"\"\n",
    "        for ln in lines:\n",
    "            lower = ln.strip().lower()\n",
    "            if lower.startswith('grade:'):\n",
    "                grade_line = ln.strip()\n",
    "            elif lower.startswith('justification:'):\n",
    "                justification_line = ln.strip()\n",
    "            elif grade_line and not justification_line and ln.strip():\n",
    "                justification_line = \"Justification: \" + ln.strip()\n",
    "        if grade_line:\n",
    "            print(grade_line)\n",
    "        if justification_line:\n",
    "            print(justification_line)\n",
    "        if not grade_line or not justification_line:\n",
    "            print(grading_text)\n",
    "        # Ask user for next action to set continue_flag\n",
    "        try:\n",
    "            choice = input(\"\\nWhat next? (quiz=another quiz question, new=new topic, enter=exit): \").strip().lower()\n",
    "        except EOFError:\n",
    "            choice = \"\"\n",
    "        if choice == 'quiz':\n",
    "            state.continue_flag = 'quiz'\n",
    "        elif choice == 'new':\n",
    "            state.continue_flag = 'new'\n",
    "        else:\n",
    "            state.continue_flag = None\n",
    "        state.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Next action choice: {choice or 'exit'}\",\n",
    "            \"action\": \"post_feedback_choice\"\n",
    "        })\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb6aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "\"\"\"\n",
    "healthAiBot graph definition.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "try:\n",
    "    from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage, BaseMessage\n",
    "except ImportError:  # Fallback if package structure differs\n",
    "    from langchain.schema import SystemMessage, HumanMessage, AIMessage, BaseMessage  # type: ignore\n",
    "    try:\n",
    "        from langchain.schema import ToolMessage  # type: ignore\n",
    "    except ImportError:  # Define minimal ToolMessage\n",
    "        class ToolMessage(HumanMessage):  # type: ignore\n",
    "            def __init__(self, content: str, name: str, tool_call_id: str = \"\"):\n",
    "                super().__init__(content=content)\n",
    "                self.name = name\n",
    "                self.tool_call_id = tool_call_id\n",
    "\n",
    "\n",
    "# Feedback router for conditional graph edges after present_feedback\n",
    "def feedback_router(state: HealthBotState):\n",
    "    if state.continue_flag == 'quiz':\n",
    "        return \"create_quiz\"\n",
    "    elif state.continue_flag == 'new':\n",
    "        return \"reset_topic_state\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "def build_healthbot_graph(model) -> StateGraph:\n",
    "    \"\"\"\n",
    "    Build the HealthBot graph with nodes and transitions, using HealthBotState and ToolNode for Tavily search.\n",
    "    \"\"\"\n",
    "    helper = GraphHelper()\n",
    "    graph = StateGraph(HealthBotState)\n",
    "\n",
    "    # Real ToolNode usage with tavily_search_tool defined as a LangChain tool.\n",
    "    tool_node = ToolNode([tavily_search_tool])\n",
    "\n",
    "    def ensure_tool_call(state: HealthBotState) -> HealthBotState:\n",
    "        \"\"\"Ensure there is an AIMessage with a tool call for tavily_search_tool.\n",
    "\n",
    "        Converts legacy dict messages to LangChain message objects if needed so ToolNode can parse them.\n",
    "        \"\"\"\n",
    "        if not state.messages:\n",
    "            return state\n",
    "\n",
    "        # If messages are dicts, convert them.\n",
    "        if not isinstance(state.messages[0], BaseMessage):\n",
    "            converted = []\n",
    "            for m in state.messages:\n",
    "                role = m.get(\"role\")\n",
    "                content = m.get(\"content\", \"\")\n",
    "                if role == \"system\":\n",
    "                    converted.append(SystemMessage(content=content))\n",
    "                elif role == \"user\":\n",
    "                    converted.append(HumanMessage(content=content))\n",
    "                elif role == \"assistant\":\n",
    "                    tool_calls = m.get(\"tool_calls\") or []\n",
    "                    lc_tool_calls = []\n",
    "                    for tc in tool_calls:\n",
    "                        args = tc.get(\"arguments\") or tc.get(\"args\") or {}\n",
    "                        if isinstance(args, str):\n",
    "                            try:\n",
    "                                args = json.loads(args)\n",
    "                            except Exception:\n",
    "                                args = {\"raw\": args}\n",
    "                        lc_tool_calls.append({\n",
    "                            \"id\": tc.get(\"id\"),\n",
    "                            \"name\": tc.get(\"name\"),\n",
    "                            \"args\": args,\n",
    "                        })\n",
    "                    converted.append(AIMessage(content=content, tool_calls=lc_tool_calls))\n",
    "                elif role == \"tool\":\n",
    "                    converted.append(ToolMessage(content=content, name=m.get(\"name\", \"tool\"), tool_call_id=m.get(\"id\") or m.get(\"tool_call_id\", \"\")))\n",
    "                else:\n",
    "                    converted.append(HumanMessage(content=content))\n",
    "            state.messages = converted\n",
    "\n",
    "        # Now operate on LangChain messages\n",
    "        last = state.messages[-1]\n",
    "        if isinstance(last, AIMessage):\n",
    "            if not getattr(last, 'tool_calls', None):\n",
    "                last.tool_calls = [{\n",
    "                    \"id\": \"auto_tavily_\" + str(datetime.now().timestamp()),\n",
    "                    \"name\": \"tavily_search_tool\",\n",
    "                    \"args\": {\"topic\": state.topic}\n",
    "                }]\n",
    "        else:\n",
    "            # Append a new AIMessage with tool call\n",
    "            state.messages.append(AIMessage(content=f\"Initiating search for {state.topic}\", tool_calls=[{\n",
    "                \"id\": \"auto_tavily_\" + str(datetime.now().timestamp()),\n",
    "                \"name\": \"tavily_search_tool\",\n",
    "                \"args\": {\"topic\": state.topic}\n",
    "            }]))\n",
    "        return state\n",
    "\n",
    "    def process_tool_output(state: HealthBotState) -> HealthBotState:\n",
    "        \"\"\"Extract last tool message content into state.search_results for downstream summarization.\"\"\"\n",
    "        # Search from end for a ToolMessage (LangChain) first\n",
    "        found = False\n",
    "        for msg in reversed(state.messages):\n",
    "            if isinstance(msg, ToolMessage):\n",
    "                state.search_results = msg.content\n",
    "                found = True\n",
    "                break\n",
    "            # Legacy dict form\n",
    "            if isinstance(msg, dict) and msg.get(\"role\") == \"tool\":\n",
    "                state.search_results = msg.get(\"content\", \"\")\n",
    "                found = True\n",
    "                break\n",
    "        if not found or not state.search_results:\n",
    "            # Fallback: invoke tool directly\n",
    "            try:\n",
    "                import os\n",
    "                if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "                    state.search_results = \"Missing Tavily API key. Please export TAVILY_API_KEY to enable search.\"\n",
    "                else:\n",
    "                    # Prefer direct call; tavily_search_tool supports .invoke when decorated\n",
    "                    if hasattr(tavily_search_tool, 'invoke'):\n",
    "                        fallback_result = tavily_search_tool.invoke({\"topic\": state.topic})\n",
    "                    else:\n",
    "                        fallback_result = tavily_search_tool(state.topic or \"\")\n",
    "                    state.search_results = str(fallback_result)\n",
    "                    # Record as ToolMessage for consistency\n",
    "                    state.messages.append(ToolMessage(content=f\"(Fallback) Search completed for {state.topic}.\", name=\"tavily_search_tool\", tool_call_id=\"fallback\"))\n",
    "            except Exception as e:\n",
    "                state.search_results = f\"No search results captured and fallback failed: {e}\"\n",
    "        return state\n",
    "\n",
    "    def reset_topic_state(state: HealthBotState) -> HealthBotState:\n",
    "        \"\"\"Clear topic-specific fields before starting a new topic cycle.\"\"\"\n",
    "        state.focus = None\n",
    "        state.search_results = None\n",
    "        state.summary = None\n",
    "        state.quiz_question = None\n",
    "        state.quiz_answer = None\n",
    "        state.grading = None\n",
    "        state.previous_questions = []\n",
    "        state.continue_flag = None\n",
    "        # Do not clear messages entirely to retain audit trail; append a separator marker\n",
    "        try:\n",
    "            from langchain_core.messages import HumanMessage  # type: ignore\n",
    "            state.messages.append(HumanMessage(content=\"--- NEW TOPIC ---\"))\n",
    "        except Exception:\n",
    "            state.messages.append({\"role\": \"user\", \"content\": \"--- NEW TOPIC ---\"})\n",
    "        return state\n",
    "\n",
    "    # Add all nodes to the graph\n",
    "    # Core information gathering & presentation nodes\n",
    "    graph.add_node(\"ask_patient\", helper.ask_patient)\n",
    "    graph.add_node(\"generate_assistant_message\", helper.generate_assistant_message)\n",
    "    graph.add_node(\"ensure_tool_call\", ensure_tool_call)\n",
    "    graph.add_node(\"search_tavily\", tool_node)\n",
    "    graph.add_node(\"process_tool_output\", process_tool_output)\n",
    "    graph.add_node(\"ask_for_focus\", helper.ask_for_focus)\n",
    "    graph.add_node(\"summarize_results\", helper.summarize_results)\n",
    "    graph.add_node(\"present_summary\", helper.present_summary)\n",
    "    graph.add_node(\"comprehension_prompt\", helper.comprehension_prompt)\n",
    "\n",
    "    # Quiz / feedback flow nodes (previously unwired)\n",
    "    graph.add_node(\"create_quiz\", helper.create_quiz)\n",
    "    graph.add_node(\"present_quiz\", helper.present_quiz)\n",
    "    graph.add_node(\"get_quiz_answer\", helper.get_quiz_answer)\n",
    "    graph.add_node(\"grade_quiz\", helper.grade_quiz)\n",
    "    graph.add_node(\"present_feedback\", helper.present_feedback)\n",
    "    graph.add_node(\"reset_topic_state\", reset_topic_state)\n",
    "    graph.add_edge(\"ask_patient\", \"generate_assistant_message\")\n",
    "    graph.add_edge(\"generate_assistant_message\", \"ensure_tool_call\")\n",
    "    graph.add_edge(\"ensure_tool_call\", \"search_tavily\")\n",
    "    graph.add_edge(\"search_tavily\", \"process_tool_output\")\n",
    "    graph.add_edge(\"process_tool_output\", \"ask_for_focus\")\n",
    "    graph.add_edge(\"ask_for_focus\", \"summarize_results\")\n",
    "    graph.add_edge(\"summarize_results\", \"present_summary\")\n",
    "    graph.add_edge(\"present_summary\", \"comprehension_prompt\")\n",
    "\n",
    "    # After comprehension prompt we always generate one quiz for now.\n",
    "    # If future logic sets continue_flag we can branch using a conditional edge.\n",
    "    graph.add_edge(\"comprehension_prompt\", \"create_quiz\")\n",
    "    graph.add_edge(\"create_quiz\", \"present_quiz\")\n",
    "    graph.add_edge(\"present_quiz\", \"get_quiz_answer\")\n",
    "    graph.add_edge(\"get_quiz_answer\", \"grade_quiz\")\n",
    "    graph.add_edge(\"grade_quiz\", \"present_feedback\")\n",
    "    # Conditional routing after feedback: END (default) | quiz (new question) | new (restart)\n",
    "    graph.add_conditional_edges(\n",
    "        \"present_feedback\",\n",
    "        feedback_router,\n",
    "        {\n",
    "            \"create_quiz\": \"create_quiz\",  # repeat quiz with new question\n",
    "            \"reset_topic_state\": \"reset_topic_state\",  # reset then new topic\n",
    "            END: END,\n",
    "        },\n",
    "    )\n",
    "    # After resetting topic-specific state, return to ask_patient for a fresh cycle\n",
    "    graph.add_edge(\"reset_topic_state\", \"ask_patient\")\n",
    "    graph.set_entry_point(\"ask_patient\")\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "669a9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "\"\"\"\n",
    "HealthBot Command Line Interface (CLI)\n",
    "This script provides a command-line interface for interacting with the HealthBot application.\n",
    "Users can specify various parameters such as the LLM backend, model name, and temperature.\n",
    "\"\"\"\n",
    "\n",
    "#import argparse\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the HealthBot CLI.\n",
    "    \"\"\"\n",
    "\n",
    "    llm_type = \"ollama\"\n",
    "    model_name = \"gemma3:1b\"\n",
    "    temperature = 0.3\n",
    "\n",
    "    healthbot = HealthBotUtils(\n",
    "        llm_type=llm_type,\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    llm = healthbot.get_llm()\n",
    "\n",
    "\n",
    "    graph = build_healthbot_graph(llm)\n",
    "    app = graph.compile()\n",
    "\n",
    "    print(\"Welcome to HealthBot!\")\n",
    "    # Single invocation; looping & quiz handled internally by graph via continue_flag routing\n",
    "    state = healthbot.reset_state(llm)\n",
    "    state = app.invoke(state, config={\"recursion_limit\": 100})\n",
    "    # If user chose to start a new topic or additional quizzes, the graph's conditional edges manage it;\n",
    "    # CLI exits after first completed flow.\n",
    "    print(\"\\nThank you for using HealthBot. Stay healthy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c27939-9687-4f0e-b5c4-2b4c7f83e891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to HealthBot!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What health topic or medical condition would you like to learn about?  common cold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to learn about: common cold\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to focus on a specific aspect (e.g., symptoms, treatment, prevention)? If yes, enter it, otherwise press Enter:  symptoms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is a summary of what you asked about:\n",
      "\n",
      "The search results indicate that the common cold is a frequently discussed illness, with several resources providing information about its symptoms, potential causes, and management. The Wikipedia page offers a basic overview of the disease, including its viral nature and common symptoms like runny nose, nasal congestion, and sneezing. The CDC website details the typical symptoms and offers recommendations for managing cold symptoms, including over-the-counter medications and probiotics. The MedlinePlus encyclopedia provides a more detailed explanation of the disease, including its potential causes and diagnostic considerations, while also including information about the most common symptoms and remedies. The PMC article delves deeper into the underlying mechanisms of the common cold, including its relationship to allergies and asthma, and offers insights into potential preventative measures.\n",
      "\n",
      "The search results provide a range of perspectives on the common cold, including its prevalence, symptoms, and potential treatments. The information presented suggests that the common cold is a relatively common illness, affecting a significant number of individuals annually. The resources highlight the importance of recognizing the typical symptoms, such as nasal congestion and sneezing, and offering guidance on symptom relief. The information also touches upon the potential role of probiotics in preventing colds, which is a noteworthy detail considering the frequent occurrence of colds.\n",
      "\n",
      "The search results do not provide information about the specific diagnostic criteria for the common cold. The resources do not offer any specific tests or procedures used to determine if a person has a common cold. The information presented is focused on the disease itself, including its symptoms, potential causes, and management strategies.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter when you are ready to take a comprehension check. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quiz Question:\n",
      "\n",
      "What is the primary focus of the search results regarding the common cold?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your answer to the quiz question:  symptoms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your grade and feedback:\n",
      "\n",
      "Grade: B\n",
      "Justification: The summary describes the search results as focusing on the disease itself, including its symptoms, potential causes, and management strategies.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "What next? (quiz=another quiz question, new=new topic, enter=exit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for using HealthBot. Stay healthy!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
