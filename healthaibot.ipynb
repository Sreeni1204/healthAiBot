{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc44fe0c",
   "metadata": {},
   "source": [
    "# HealthAIBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f0f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export env variables before running this block\n",
    "import os\n",
    "\n",
    "class KEYS:\n",
    "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-openai-api-key\")\n",
    "    TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\", \"your-tavily-api-key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4e6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "# healthAiBot/healthaibot/utils/utils.py\n",
    "\"\"\"\n",
    "Utility functions for HealthBot operations.\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Any, Dict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "class HealthBotState(BaseModel):\n",
    "    messages: List[Dict[str, str]] = Field(\n",
    "        default_factory=list, \n",
    "        description=\"List of conversation messages including tool calls for traceability\"\n",
    "    )\n",
    "    topic: Optional[str] = None\n",
    "    focus: Optional[str] = None\n",
    "    search_results: Optional[str] = None\n",
    "    summary: Optional[str] = None\n",
    "    question: Optional[str] = None\n",
    "    quiz_question: Optional[str] = None\n",
    "    quiz_answer: Optional[str] = None\n",
    "    quiz_grade: Optional[str] = None\n",
    "    grading: Optional[str] = None\n",
    "    continue_flag: Optional[str] = None\n",
    "    previous_questions: List[str] = Field(default_factory=list)\n",
    "    tool_call_events: List[Any] = Field(\n",
    "        default_factory=list, \n",
    "        description=\"Legacy tool call tracking - use messages for better traceability\"\n",
    "    )\n",
    "    llm: Optional[Any] = None\n",
    "\n",
    "\n",
    "class HealthBotUtils:\n",
    "    \"\"\"\n",
    "    Utility functions for HealthBot operations.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_type: str,\n",
    "        model_name: str,\n",
    "        temperature: float = 0.7,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the HealthBotUtils class.\n",
    "        Parameters:\n",
    "            llm_type: Type of LLM to use ('openai' or 'ollama').\n",
    "            model_name: Name of the model to use.\n",
    "            temperature: Sampling temperature for the LLM.\n",
    "        \"\"\"\n",
    "        self.llm_type = llm_type\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def get_llm(\n",
    "        self,\n",
    "    ) -> ChatOpenAI | ChatOllama:\n",
    "        \"\"\"\n",
    "        Get the LLM instance based on the specified type.\n",
    "        Returns:\n",
    "            An instance of ChatOpenAI or ChatOllama.\n",
    "        \"\"\"\n",
    "        if self.llm_type == \"openai\":\n",
    "            return ChatOpenAI(\n",
    "                model=self.model_name,\n",
    "                temperature=self.temperature\n",
    "            )\n",
    "        elif self.llm_type == \"ollama\":\n",
    "            return ChatOllama(\n",
    "                model=self.model_name,\n",
    "                temperature=self.temperature\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported LLM type. Choose 'openai' or 'ollama'.\")\n",
    "\n",
    "    def reset_state(\n",
    "        self,\n",
    "        llm: ChatOpenAI | ChatOllama,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Reset the state of the HealthBot.\n",
    "        \"\"\"\n",
    "        # Clear previous health information to maintain privacy\n",
    "        return HealthBotState(llm=llm)\n",
    "\n",
    "    def parse_quiz(\n",
    "        self,\n",
    "        quiz_text: str,\n",
    "    ) -> tuple[str, list[str]]:\n",
    "        \"\"\"\n",
    "        Parse the quiz text into a question and options.\n",
    "        Now handles both single questions and multiple choice questions.\n",
    "        \"\"\"\n",
    "        # Simple parser to split question and options\n",
    "        lines = quiz_text.strip().split('\\n')\n",
    "        question = \"\"\n",
    "        options = []\n",
    "        \n",
    "        for line in lines:\n",
    "            # Check for multiple choice options\n",
    "            if line.startswith(\"a)\") or line.startswith(\"b)\") or line.startswith(\"c)\") or line.startswith(\"d)\"):\n",
    "                options.append(line)\n",
    "            elif line.lower().startswith(\"question:\"):\n",
    "                question = line[len(\"Question:\"):].strip()\n",
    "            elif line and not line.startswith(\"summary:\") and not line.startswith(\"previous questions:\"):\n",
    "                if question:\n",
    "                    question += \" \" + line.strip()\n",
    "                else:\n",
    "                    question = line.strip()\n",
    "        \n",
    "        # If no options found, this is a single question (not MCQ)\n",
    "        # Return empty options list to indicate open-ended question\n",
    "        return question.strip(), options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4596a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "# healthAiBot/healthaibot/utils/agent_utils.py\n",
    "\"\"\"\n",
    "Utility functions for HealthBot agent operations.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Optional, Callable\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "\n",
    "def tavily_search_tool(topic: str) -> str:\n",
    "    \"\"\"Search for medical information from trusted sources like NIH, Mayo Clinic, and WebMD.\"\"\"\n",
    "    search = TavilySearch()\n",
    "    query = f\"{topic} site:nih.gov OR site:mayoclinic.org OR site:webmd.com\"\n",
    "    return search.invoke(query)\n",
    "\n",
    "\n",
    "class GraphHelper:\n",
    "    \"\"\"\n",
    "    Helper class for managing graph-related operations.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize with the current state.\n",
    "        \"\"\"\n",
    "\n",
    "    def ask_patient(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Prompt the user for a health topic and update the state.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            topic = input(\"What health topic or medical condition would you like to learn about? \")\n",
    "        except EOFError:\n",
    "            print(\"\\nInput ended unexpectedly. Exiting HealthBot.\")\n",
    "            exit(0)\n",
    "        state.topic = topic\n",
    "        print(f\"You have chosen to learn about: {state.topic}\")\n",
    "        \n",
    "        # Add user input to messages for traceability\n",
    "        user_input_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"I want to learn about {state.topic}.\",\n",
    "            \"action\": \"topic_selection\",\n",
    "            \"timestamp\": str(datetime.now())\n",
    "        }\n",
    "        state.messages.append(user_input_message)\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def generate_assistant_message(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Generate an assistant message after user input, required for ToolNode.\n",
    "        \"\"\"\n",
    "        # Set context and messages\n",
    "        state.messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful medical information assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"I want to learn about {state.topic}.\"},\n",
    "            {\"role\": \"assistant\", \"content\": f\"I'll search for accurate information about {state.topic} from reliable medical sources. Let me use the search tool to find relevant details.\"}\n",
    "        ]\n",
    "        return state\n",
    "\n",
    "    def ask_for_focus(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Ask the user if they want to focus on a specific aspect.\n",
    "        \"\"\"\n",
    "        if not state.focus:\n",
    "            try:\n",
    "                focus = input(\"Do you want to focus on a specific aspect (e.g., symptoms, treatment, prevention)? If yes, enter it, otherwise press Enter: \")\n",
    "            except EOFError:\n",
    "                print(\"\\nInput ended unexpectedly. Using no specific focus.\")\n",
    "                focus = \"\"\n",
    "            if focus.strip():\n",
    "                state.focus = focus.strip()\n",
    "                \n",
    "            # Add focus selection to messages for traceability\n",
    "            focus_message = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Focus selection: {state.focus if state.focus else 'No specific focus'}\",\n",
    "                \"action\": \"focus_selection\",\n",
    "                \"timestamp\": str(datetime.now())\n",
    "            }\n",
    "            state.messages.append(focus_message)\n",
    "            \n",
    "        return state\n",
    "\n",
    "    def ask_for_focus(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Ask the user if they want to focus on a specific aspect.\n",
    "        \"\"\"\n",
    "        if not state.focus:\n",
    "            try:\n",
    "                focus = input(\"Do you want to focus on a specific aspect (e.g., symptoms, treatment, prevention)? If yes, enter it, otherwise press Enter: \")\n",
    "            except EOFError:\n",
    "                print(\"\\nInput ended unexpectedly. Using no specific focus.\")\n",
    "                focus = \"\"\n",
    "            if focus.strip():\n",
    "                state.focus = focus.strip()\n",
    "        return state\n",
    "\n",
    "    def search_tavily(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Search for relevant information using the Tavily ToolNode.\n",
    "        Record tool call event in state.\n",
    "        \"\"\"\n",
    "        # Example event recording (actual tool call handled by ToolNode)\n",
    "        event = {\n",
    "            \"event\": \"tool_call\",\n",
    "            \"tool\": \"tavily_search_tool\",\n",
    "            \"topic\": state.topic\n",
    "        }\n",
    "        state.tool_call_events.append(event)\n",
    "        return state\n",
    "\n",
    "    def summarize_results(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Summarize the search results using the LLM.\n",
    "        Enforce: summary must be exactly 3–4 paragraphs, use no outside knowledge, and be strictly based on tool output.\n",
    "        \"\"\"\n",
    "        llm = state.llm\n",
    "        focus = getattr(state, 'focus', None)\n",
    "        \n",
    "        base_prompt = (\n",
    "            \"You are a medical information assistant. Your task is to summarize the provided search results for a patient.\\n\\n\"\n",
    "            \"STRICT REQUIREMENTS:\\n\"\n",
    "            \"1. Write EXACTLY 3-4 paragraphs - no more, no less\\n\"\n",
    "            \"2. Use ONLY the information provided in the search results below\\n\"\n",
    "            \"3. Do NOT add any outside knowledge, personal opinions, or information not found in the search results\\n\"\n",
    "            \"4. Write in simple, patient-friendly language\\n\"\n",
    "            \"5. Each paragraph should be 3-5 sentences long\\n\"\n",
    "            \"6. If information is missing from the search results, explicitly state 'The search results do not provide information about [topic]'\\n\\n\"\n",
    "        )\n",
    "        \n",
    "        if focus:\n",
    "            base_prompt += f\"FOCUS REQUIREMENT: Emphasize information about '{focus}' while maintaining the 3-4 paragraph structure.\\n\\n\"\n",
    "        \n",
    "        base_prompt += (\n",
    "            \"FORMAT: Write exactly 3-4 paragraphs separated by blank lines. Do not include headers, bullet points, or numbered lists.\\n\\n\"\n",
    "            \"SEARCH RESULTS TO SUMMARIZE:\\n\"\n",
    "        )\n",
    "        \n",
    "        prompt = base_prompt + state.search_results\n",
    "        \n",
    "        # Add LLM request to messages for traceability\n",
    "        llm_request_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Requesting summary generation for topic: {state.topic}\",\n",
    "            \"action\": \"summarize_results\",\n",
    "            \"focus\": focus if focus else \"None\"\n",
    "        }\n",
    "        state.messages.append(llm_request_message)\n",
    "        \n",
    "        summary = llm.invoke(prompt)\n",
    "        # Extract content from AIMessage if needed\n",
    "        if hasattr(summary, 'content'):\n",
    "            state.summary = summary.content\n",
    "        else:\n",
    "            state.summary = str(summary)\n",
    "            \n",
    "        # Add LLM response to messages for traceability\n",
    "        llm_response_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Generated summary for {state.topic} ({len(state.summary)} characters)\",\n",
    "            \"action\": \"summarize_results_complete\",\n",
    "            \"summary_length\": str(len(state.summary))\n",
    "        }\n",
    "        state.messages.append(llm_response_message)\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def present_summary(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Present the summarized information to the user.\n",
    "        \"\"\"\n",
    "        print(\"\\nHere is a summary of what you asked about:\\n\")\n",
    "        print(state.summary)\n",
    "        return state\n",
    "\n",
    "    def comprehension_prompt(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Prompt the user for a comprehension check.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            input(\"\\nPress Enter when you are ready to take a comprehension check.\")\n",
    "        except EOFError:\n",
    "            print(\"\\nInput ended unexpectedly. Proceeding with comprehension check.\")\n",
    "        return state\n",
    "\n",
    "    def create_quiz(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Create a quiz based on the current state.\n",
    "        Enforce: quiz must be based only on the summary, single question, and answerable using summary alone.\n",
    "        \"\"\"\n",
    "        llm = state.llm\n",
    "        previous_questions = getattr(state, 'previous_questions', [])\n",
    "        \n",
    "        prompt = (\n",
    "            \"Create ONE comprehension question based EXCLUSIVELY on the provided summary below.\\n\\n\"\n",
    "            \"STRICT REQUIREMENTS:\\n\"\n",
    "            \"1. Create ONLY ONE question - not multiple choice, just a single question\\n\"\n",
    "            \"2. The question must be answerable ONLY using information from the summary\\n\"\n",
    "            \"3. Do NOT use any outside knowledge or information not in the summary\\n\"\n",
    "            \"4. The question should test understanding of key information from the summary\\n\"\n",
    "            \"5. Do NOT reveal the correct answer in your response\\n\"\n",
    "            \"6. Do NOT repeat any of the previous questions listed below\\n\\n\"\n",
    "            \"QUESTION TYPES (choose the most appropriate):\\n\"\n",
    "            \"- What is/are... (factual questions)\\n\"\n",
    "            \"- Why does/is... (explanation questions)\\n\"\n",
    "            \"- How does/can... (process questions)\\n\"\n",
    "            \"- Which statement best describes... (comprehension questions)\\n\\n\"\n",
    "            \"FORMAT: Provide only the question text, nothing else.\\n\\n\"\n",
    "            f\"SUMMARY TO BASE QUESTION ON:\\n{state.summary}\\n\\n\"\n",
    "            f\"PREVIOUS QUESTIONS TO AVOID:\\n{previous_questions if previous_questions else 'None'}\\n\\n\"\n",
    "            \"YOUR SINGLE QUESTION:\"\n",
    "        )\n",
    "        \n",
    "        # Add quiz creation request to messages for traceability\n",
    "        quiz_request_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Requesting quiz question generation for topic: {state.topic}\",\n",
    "            \"action\": \"create_quiz\",\n",
    "            \"previous_questions_count\": str(len(previous_questions))\n",
    "        }\n",
    "        state.messages.append(quiz_request_message)\n",
    "        \n",
    "        quiz_question = llm.invoke(prompt)\n",
    "        # Extract content from AIMessage if needed\n",
    "        if hasattr(quiz_question, 'content'):\n",
    "            state.quiz_question = quiz_question.content\n",
    "        else:\n",
    "            state.quiz_question = str(quiz_question)\n",
    "            \n",
    "        # Add quiz creation response to messages for traceability\n",
    "        quiz_response_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Generated quiz question for {state.topic}\",\n",
    "            \"action\": \"create_quiz_complete\",\n",
    "            \"question_preview\": state.quiz_question[:100] + \"...\" if len(state.quiz_question) > 100 else state.quiz_question\n",
    "        }\n",
    "        state.messages.append(quiz_response_message)\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def present_quiz(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Present the quiz question to the user.\n",
    "        \"\"\"\n",
    "        print(\"\\nQuiz Question:\\n\")\n",
    "        print(state.quiz_question)\n",
    "        return state\n",
    "\n",
    "    def get_quiz_answer(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Get the user's answer to the quiz question.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            answer = input(\"\\nEnter your answer to the quiz question: \")\n",
    "        except EOFError:\n",
    "            print(\"\\nInput ended unexpectedly. Exiting HealthBot.\")\n",
    "            exit(0)\n",
    "        state.quiz_answer = answer\n",
    "        \n",
    "        # Add user's quiz answer to messages for traceability\n",
    "        quiz_answer_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Quiz answer: {answer}\",\n",
    "            \"action\": \"quiz_answer_submission\",\n",
    "            \"question\": state.quiz_question,\n",
    "            \"timestamp\": str(datetime.now())\n",
    "        }\n",
    "        state.messages.append(quiz_answer_message)\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def grade_quiz(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Grade the user's answer to the quiz question.\n",
    "        Enforce: use only the summary, output letter grade (A–F) plus brief justification.\n",
    "        \"\"\"\n",
    "        llm = state.llm\n",
    "        prompt = (\n",
    "            \"You are grading a comprehension question. You must provide EXACTLY a letter grade (A, B, C, D, or F) and justification.\\n\\n\"\n",
    "            \"CRITICAL REQUIREMENTS:\\n\"\n",
    "            \"1. You MUST output a letter grade: A, B, C, D, or F (no other grades allowed)\\n\"\n",
    "            \"2. Use EXCLUSIVELY the information from the summary below - absolutely NO outside knowledge\\n\"\n",
    "            \"3. Your justification must ONLY reference information that appears in the summary\\n\"\n",
    "            \"4. If the answer contradicts the summary, grade it lower\\n\"\n",
    "            \"5. If the answer matches information in the summary, grade it higher\\n\"\n",
    "            \"6. Do NOT add any information not found in the summary\\n\\n\"\n",
    "            \"GRADING SCALE:\\n\"\n",
    "            \"A = Completely accurate based on summary information\\n\"\n",
    "            \"B = Mostly accurate with minor gaps based on summary\\n\"\n",
    "            \"C = Partially accurate but missing key summary points\\n\"\n",
    "            \"D = Limited accuracy, contradicts some summary information\\n\"\n",
    "            \"F = Incorrect or completely contradicts the summary\\n\\n\"\n",
    "            \"REQUIRED FORMAT (follow exactly):\\n\"\n",
    "            \"Grade: [single letter A, B, C, D, or F]\\n\"\n",
    "            \"Justification: [1-2 sentences explaining the grade based ONLY on summary content]\\n\\n\"\n",
    "            \"SUMMARY (your ONLY data source):\\n\"\n",
    "            f\"{state.summary}\\n\\n\"\n",
    "            \"QUESTION:\\n\"\n",
    "            f\"{state.quiz_question}\\n\\n\"\n",
    "            \"STUDENT'S ANSWER:\\n\"\n",
    "            f\"{state.quiz_answer}\\n\\n\"\n",
    "            \"PROVIDE YOUR GRADE AND JUSTIFICATION:\"\n",
    "        )\n",
    "        \n",
    "        # Add grading request to messages for traceability\n",
    "        grading_request_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Requesting grade for quiz answer on topic: {state.topic}\",\n",
    "            \"action\": \"grade_quiz\",\n",
    "            \"user_answer\": state.quiz_answer\n",
    "        }\n",
    "        state.messages.append(grading_request_message)\n",
    "        \n",
    "        grading = llm.invoke(prompt)\n",
    "        # Extract content from AIMessage if needed\n",
    "        if hasattr(grading, 'content'):\n",
    "            state.grading = grading.content\n",
    "        else:\n",
    "            state.grading = str(grading)\n",
    "            \n",
    "        # Add grading response to messages for traceability\n",
    "        grading_response_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Completed grading for {state.topic} quiz question\",\n",
    "            \"action\": \"grade_quiz_complete\",\n",
    "            \"grading_preview\": state.grading[:100] + \"...\" if len(state.grading) > 100 else state.grading\n",
    "        }\n",
    "        state.messages.append(grading_response_message)\n",
    "        \n",
    "        return state\n",
    "\n",
    "    def present_feedback(\n",
    "        self,\n",
    "        state: HealthBotState,\n",
    "    ) -> HealthBotState:\n",
    "        \"\"\"\n",
    "        Present the feedback to the user with proper grade formatting.\n",
    "        \"\"\"\n",
    "        print(\"\\nYour grade and feedback:\\n\")\n",
    "        \n",
    "        # Ensure the grading follows the required format\n",
    "        grading_text = state.grading\n",
    "        \n",
    "        # Extract grade and justification if they're properly formatted\n",
    "        lines = grading_text.strip().split('\\n')\n",
    "        grade_line = \"\"\n",
    "        justification_line = \"\"\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().lower().startswith('grade:'):\n",
    "                grade_line = line.strip()\n",
    "            elif line.strip().lower().startswith('justification:'):\n",
    "                justification_line = line.strip()\n",
    "            elif grade_line and not justification_line and line.strip():\n",
    "                # If we have a grade but no explicit justification line, treat this as justification\n",
    "                justification_line = \"Justification: \" + line.strip()\n",
    "        \n",
    "        # Display the formatted feedback\n",
    "        if grade_line:\n",
    "            print(grade_line)\n",
    "        if justification_line:\n",
    "            print(justification_line)\n",
    "        \n",
    "        # If formatting is not as expected, display the raw grading\n",
    "        if not grade_line or not justification_line:\n",
    "            print(grading_text)\n",
    "        \n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb6aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "\"\"\"\n",
    "healthAiBot graph definition.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Feedback router for conditional graph edges after present_feedback\n",
    "def feedback_router(state: HealthBotState):\n",
    "    if state.continue_flag == 'quiz':\n",
    "        return \"create_quiz\"\n",
    "    elif state.continue_flag == 'new':\n",
    "        return \"ask_patient\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "def build_healthbot_graph(model) -> StateGraph:\n",
    "    \"\"\"\n",
    "    Build the HealthBot graph with nodes and transitions, using HealthBotState and ToolNode for Tavily search.\n",
    "    \"\"\"\n",
    "    helper = GraphHelper()\n",
    "    graph = StateGraph(HealthBotState)\n",
    "\n",
    "    # Create a custom search function that works with the state\n",
    "    def search_tavily_node(state: HealthBotState) -> HealthBotState:\n",
    "        \"\"\"Execute Tavily search and store results in state with message traceability.\"\"\"\n",
    "        try:\n",
    "            # Add tool call message for traceability\n",
    "            tool_call_message = {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"I'm searching for information about {state.topic} using Tavily search tool.\",\n",
    "                \"tool_call_name\": \"tavily_search_tool\",\n",
    "                \"tool_call_arguments\": state.topic,\n",
    "                \"timestamp\": str(datetime.now())\n",
    "            }\n",
    "            state.messages.append(tool_call_message)\n",
    "            \n",
    "            # Execute the search\n",
    "            results = tavily_search_tool(state.topic)\n",
    "            state.search_results = str(results)\n",
    "            \n",
    "            # Add tool response message for traceability\n",
    "            tool_response_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": \"tavily_search_tool\",\n",
    "                \"content\": f\"Search completed for {state.topic}. Found {len(str(results))} characters of information.\",\n",
    "                \"tool_call_id\": f\"tavily_search_{state.topic}_{datetime.now().timestamp()}\"\n",
    "            }\n",
    "            state.messages.append(tool_response_message)\n",
    "            \n",
    "        except Exception as e:\n",
    "            state.search_results = f\"Error searching for {state.topic}: {str(e)}\"\n",
    "            # Add error message for traceability\n",
    "            error_message = {\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": \"tavily_search_tool\",\n",
    "                \"content\": f\"Error occurred during search: {str(e)}\",\n",
    "                \"error\": \"True\"\n",
    "            }\n",
    "            state.messages.append(error_message)\n",
    "        return state\n",
    "\n",
    "    # Add all nodes to the graph\n",
    "    graph.add_node(\"ask_patient\", helper.ask_patient)\n",
    "    graph.add_node(\"generate_assistant_message\", helper.generate_assistant_message)\n",
    "    graph.add_node(\"search_tavily\", search_tavily_node)\n",
    "    graph.add_node(\"ask_for_focus\", helper.ask_for_focus)\n",
    "    graph.add_node(\"summarize_results\", helper.summarize_results)\n",
    "    graph.add_node(\"present_summary\", helper.present_summary)\n",
    "    graph.add_node(\"comprehension_prompt\", helper.comprehension_prompt)\n",
    "    graph.add_edge(\"ask_patient\", \"generate_assistant_message\")\n",
    "    graph.add_edge(\"generate_assistant_message\", \"search_tavily\")\n",
    "    graph.add_edge(\"search_tavily\", \"ask_for_focus\")\n",
    "    graph.add_edge(\"ask_for_focus\", \"summarize_results\")\n",
    "    graph.add_edge(\"summarize_results\", \"present_summary\")\n",
    "    graph.add_edge(\"present_summary\", \"comprehension_prompt\")\n",
    "    # Properly terminate the graph workflow\n",
    "    graph.add_edge(\"comprehension_prompt\", END)\n",
    "    graph.set_entry_point(\"ask_patient\")\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669a9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "\"\"\"\n",
    "HealthBot Command Line Interface (CLI)\n",
    "This script provides a command-line interface for interacting with the HealthBot application.\n",
    "Users can specify various parameters such as the LLM backend, model name, and temperature.\n",
    "\"\"\"\n",
    "\n",
    "#import argparse\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the HealthBot CLI.\n",
    "    \"\"\"\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(description=\"HealthBot CLI\")\n",
    "    parser.add_argument(\n",
    "        '--llm_type',\n",
    "        choices=['openai', 'ollama'],\n",
    "        default='ollama',\n",
    "        help='Choose LLM backend: openai or ollama'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--model_name',\n",
    "        type=str,\n",
    "        default='gemma3:1b',\n",
    "        help='Model name for LLM'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--temperature',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='Temperature for LLM'\n",
    "    )\n",
    "    # Add more arguments as needed\n",
    "    args = parser.parse_args()\n",
    "    '''\n",
    "\n",
    "    llm_type = \"ollama\"\n",
    "    model_name = \"gemma3:1b\"\n",
    "    temperature = 0.3\n",
    "\n",
    "    healthbot = HealthBotUtils(\n",
    "        llm_type=llm_type,\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    \n",
    "    llm = healthbot.get_llm()\n",
    "\n",
    "\n",
    "    graph = build_healthbot_graph(llm)\n",
    "    app = graph.compile()\n",
    "\n",
    "    print(\"Welcome to HealthBot!\")\n",
    "    while True:\n",
    "        state = healthbot.reset_state(llm)\n",
    "        # Run the graph workflow to execute the full flow including focus question\n",
    "        state = app.invoke(state)\n",
    "\n",
    "        # The graph already handled focus, search, summarization, and summary presentation\n",
    "        # No need to duplicate these steps here\n",
    "        \n",
    "        # Convert state back to HealthBotState if it's a dict\n",
    "        if isinstance(state, dict):\n",
    "            from healthaibot.utils.utils import HealthBotState\n",
    "            state = HealthBotState(**state)\n",
    "\n",
    "        # Track previous questions for this topic\n",
    "        if not hasattr(state, 'previous_questions'):\n",
    "            state.previous_questions = []\n",
    "        \n",
    "        # Create GraphHelper for quiz operations\n",
    "        graphhelper = GraphHelper()\n",
    "        quiz_active = True\n",
    "        while quiz_active:\n",
    "            # Create and present quiz\n",
    "            state = graphhelper.create_quiz(state)\n",
    "            question, options = healthbot.parse_quiz(state.quiz_question)\n",
    "            print(\"\\nQuiz Question:\")\n",
    "            print(question)\n",
    "            \n",
    "            # Only print options if this is a multiple choice question\n",
    "            if options:\n",
    "                for opt in options:\n",
    "                    print(opt)\n",
    "            \n",
    "            state.previous_questions.append(question)\n",
    "            state = graphhelper.get_quiz_answer(state)\n",
    "            state = graphhelper.grade_quiz(state)\n",
    "            state = graphhelper.present_feedback(state)\n",
    "\n",
    "            try:\n",
    "                next_action = input(\"Would you like to take another quiz on this topic (enter 'quiz'), learn about a new topic (enter 'new'), or exit (enter 'exit')? \")\n",
    "            except EOFError:\n",
    "                print(\"\\nInput ended unexpectedly. Thank you for using HealthBot. Stay healthy!\")\n",
    "                return\n",
    "            if next_action.lower() == 'quiz':\n",
    "                print(\"Let's take another quiz on this topic!\")\n",
    "                continue  # Stay in quiz loop\n",
    "            elif next_action.lower() == 'new':\n",
    "                print(\"Let's learn about a new topic!\")\n",
    "                quiz_active = False  # Break quiz loop, go to new topic\n",
    "            elif next_action.lower() == 'exit':\n",
    "                print(\"Thank you for using HealthBot. Stay healthy!\")\n",
    "                return\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter 'quiz', 'new', or 'exit'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c27939-9687-4f0e-b5c4-2b4c7f83e891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to HealthBot!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What health topic or medical condition would you like to learn about?  common cold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have chosen to learn about: common cold\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to focus on a specific aspect (e.g., symptoms, treatment, prevention)? If yes, enter it, otherwise press Enter:  symptoms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is a summary of what you asked about:\n",
      "\n",
      "The common cold is a viral infection of the upper respiratory tract that primarily affects the respiratory mucosa of the nose, throat, and sinuses. It’s often characterized by symptoms like a runny nose, nasal congestion, sneezing, and sore throat. These symptoms are frequently mild and can last less than a week, but they can vary in severity from person to person. The CDC provides detailed information about the common cold, including its causes, transmission, and potential treatments.\n",
      "\n",
      "The information from the CDC emphasizes that colds are typically milder than influenza (the flu) and can be caused by various viruses, including rhinoviruses, parainfluenza, and seasonal coronaviruses.  MedlinePlus offers a comprehensive resource for understanding the symptoms of a cold, including potential remedies like over-the-counter medications and probiotics.  The encyclopedia provides a detailed overview of the common cold, including its most frequent symptoms and potential causes.\n",
      "\n",
      "The provided resources detail that the most common symptoms associated with a cold are a runny nose, nasal congestion, and sneezing.  The information also highlights that the cold is often contagious, and that children can experience frequent colds throughout the year.  The resources also provide a brief overview of the most common cold symptoms and potential remedies.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Press Enter when you are ready to take a comprehension check. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quiz Question:\n",
      "What are some of the most common symptoms associated with a cold, according to the provided resources?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your answer to the quiz question:  runny nose\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your grade and feedback:\n",
      "\n",
      "Grade: F\n",
      "Justification: The summary only mentions that the cold is often contagious and that the most common symptoms are a runny nose and sneezing, but it does not specify any other symptoms.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you like to take another quiz on this topic (enter 'quiz'), learn about a new topic (enter 'new'), or exit (enter 'exit')?  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using HealthBot. Stay healthy!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
